{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w266: Final Project\n",
    "### Christopher Danicic, Robert Deng, Chandan Gope\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os, sys, re, json, time, gc, warnings\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as venn\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "import string\n",
    "from PIL import Image\n",
    "color = sns.color_palette()\n",
    "\n",
    "#SciKit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer  \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "train = pd.read_csv(\"~/w266-data/train.csv\")\n",
    "test = pd.read_csv(\"~/w266-data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       : train : test\n",
      "rows   : 159571 : 153164\n",
      "perc   : 51    : 49\n"
     ]
    }
   ],
   "source": [
    "nrow_train=train.shape[0]\n",
    "nrow_test=test.shape[0]\n",
    "sum=nrow_train+nrow_test\n",
    "print(\"       : train : test\")\n",
    "print(\"rows   :\",nrow_train,\":\",nrow_test)\n",
    "print(\"perc   :\",round(nrow_train*100/sum),\"   :\",round(nrow_test*100/sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's roughly a 50/50 split between test and train. Later, we will further segment 15% of the train data as dev data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nltk_preprocess(data):\n",
    "    '''This function preprocesses a data frame, specifing a text_column, \n",
    "    and strips down the document to cleaned, individualized word tokens without\n",
    "    stop words and other excessive parts of speech and eventually rejoins the remaining words.\n",
    "    '''\n",
    "    #Initializes stop words and new column creation\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    \n",
    "    #Initialize Lemmatizer object and final list of lemmatized words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None # for easy if-statement\n",
    "        \n",
    "    def lemmatized(word, tag):\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if wntag is None:\n",
    "            lemma = str(lemmatizer.lemmatize(word))\n",
    "        else:\n",
    "            lemma = str(lemmatizer.lemmatize(word, pos=wntag))\n",
    "        return lemma\n",
    "\n",
    "    #Remove numeric data, alpha nonnumeric symbols, ip address, new lines, and usernames\n",
    "    data = data.apply(lambda z: re.sub(r'\\d+', r' ', z))\n",
    "    data = data.apply(lambda z: re.sub(r'\\W+', r' ', z))\n",
    "    data = data.apply(lambda z: re.sub(r\"_+\",r\" \", z))\n",
    "    data = data.apply(lambda z: re.sub(\"\\\\n\",\"\", z))\n",
    "    data = data.apply(lambda z: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\", z))\n",
    "    data = data.apply(lambda z: re.sub(\"\\[\\[.*\\]\",\"\", z))\n",
    "    \n",
    "    #Decapitalize, NLTK: tokenize, remove stop words, keep relevant pos tags, and lemmatize\n",
    "    data = data.str.lower()\n",
    "    data = data.apply(word_tokenize)\n",
    "    data = data.apply(lambda x: [item for item in x if item not in stop])\n",
    "    data = data.apply(pos_tag)\n",
    "    data = data.apply(lambda x: [lemmatized(word, tag) for (word, tag) in x])\n",
    "    data = data.apply(lambda x: ' '.join(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_text (135526,) \n",
      "train_labels (135526, 6)\n",
      "\n",
      "\n",
      "dev_text (24045,) \n",
      "dev_labels (24045, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelling\n",
    "#Seeding\n",
    "np.random.seed(6)\n",
    "in_dev = np.random.choice([True, False], len(train), p=[0.15, 0.85])\n",
    "\n",
    "#Train\n",
    "train_data = train.comment_text[np.logical_not(in_dev)]\n",
    "train_labels = train.iloc[np.logical_not(in_dev), 2:8]\n",
    "\n",
    "#Dev Set\n",
    "dev_data, dev_labels = train.comment_text[in_dev], train.iloc[in_dev, 2:8]\n",
    "\n",
    "#Target Names\n",
    "target_names = train.columns[2:8]\n",
    "\n",
    "#Print some train data\n",
    "print(\"train_text\", train_data.shape, \"\\ntrain_labels\", train_labels.shape)\n",
    "print(\"\\n\\ndev_text\", dev_data.shape, \"\\ndev_labels\", dev_labels.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessed_train_data = nltk_preprocess(train_data)\n",
    "preprocessed_dev_data = nltk_preprocess(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_a...lti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_pipeline = Pipeline([('cv', CountVectorizer()),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                           ('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "toxic_pipeline_2 = Pipeline([('cv', CountVectorizer()), ('tfidf', TfidfTransformer()), ('svc', OneVsRestClassifier(LinearSVC(multi_class=\"ovr\")))])\n",
    "\n",
    "\n",
    "toxic_pipeline.fit(preprocessed_train_data, train_labels)\n",
    "toxic_pipeline_2.fit(preprocessed_train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.57      0.61      0.59      2162\n",
      " severe_toxic       0.22      0.65      0.33        79\n",
      "      obscene       0.64      0.59      0.61      1342\n",
      "       threat       0.08      0.75      0.14         8\n",
      "       insult       0.43      0.80      0.56       619\n",
      "identity_hate       0.14      0.74      0.23        38\n",
      "\n",
      "  avg / total       0.56      0.63      0.58      4248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toxic_pipeline_2 = Pipeline([('cv', CountVectorizer()),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                           ('svc', OneVsRestClassifier(LinearSVC(multi_class=\"ovr\")))])\n",
    "toxic_pipeline_2.fit(preprocessed_train_data, train_labels)\n",
    "pred_dev_2 = toxic_pipeline_2.predict(dev_data)\n",
    "print(classification_report(pred_dev_2, dev_labels, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.59      0.24      0.34      5655\n",
      " severe_toxic       0.12      0.22      0.16       129\n",
      "      obscene       0.66      0.26      0.37      3089\n",
      "       threat       0.13      0.32      0.19        31\n",
      "       insult       0.50      0.21      0.30      2735\n",
      "identity_hate       0.17      0.17      0.17       200\n",
      "\n",
      "  avg / total       0.57      0.24      0.33     11839\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.57      0.61      0.59      2162\n",
      " severe_toxic       0.22      0.65      0.33        79\n",
      "      obscene       0.64      0.59      0.61      1342\n",
      "       threat       0.08      0.75      0.14         8\n",
      "       insult       0.43      0.80      0.56       619\n",
      "identity_hate       0.14      0.74      0.23        38\n",
      "\n",
      "  avg / total       0.56      0.63      0.58      4248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_dev = toxic_pipeline.predict(dev_data)\n",
    "pred_dev_2 = toxic_pipeline_2.predict(dev_data)\n",
    "print(classification_report(pred_dev, dev_labels, target_names = target_names))\n",
    "print(classification_report(pred_dev_2, dev_labels, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.71      0.28      0.40     32480\n",
      " severe_toxic       0.46      0.63      0.53      1010\n",
      "      obscene       0.74      0.31      0.44     17069\n",
      "       threat       0.34      0.61      0.44       226\n",
      "       insult       0.64      0.28      0.39     15231\n",
      "identity_hate       0.45      0.41      0.43      1320\n",
      "\n",
      "  avg / total       0.69      0.30      0.41     67336\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.69      0.70      0.70     12842\n",
      " severe_toxic       0.35      0.86      0.50       562\n",
      "      obscene       0.75      0.67      0.71      8063\n",
      "       threat       0.20      0.94      0.33        86\n",
      "       insult       0.59      0.92      0.72      4332\n",
      "identity_hate       0.31      0.95      0.46       388\n",
      "\n",
      "  avg / total       0.68      0.73      0.69     26273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train = toxic_pipeline.predict(train_data)\n",
    "pred_train_2 = toxic_pipeline_2.predict(train_data)\n",
    "print(classification_report(pred_train, train_labels, target_names = target_names))\n",
    "print(classification_report(pred_train_2, train_labels, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-036e1ee6cc1c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-036e1ee6cc1c>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(\"pred_dev_2 confusion matrix\", confusion_matrix(pred_dev_2, dev_labels)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"pred_dev confusion matrix\", confusion_matrix(pred_dev, dev_labels)\n",
    "print(\"pred_dev_2 confusion matrix\", confusion_matrix(pred_dev_2, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146228"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        occurrences       term  frequency\n",
      "7931          63087    article   0.431429\n",
      "92724         48729       page   0.333240\n",
      "139676        41448  wikipedia   0.283448\n",
      "124123        34331       talk   0.234777\n",
      "133963        27537        use   0.188316\n",
      "37999         26265       edit   0.179617\n",
      "90535         26127        one   0.178673\n",
      "76057         25537       make   0.174638\n",
      "97164         25355     please   0.173394\n",
      "141125        25020      would   0.171103\n",
      "72979         24432       like   0.167082\n",
      "111195        21752        say   0.148754\n",
      "112540        21663        see   0.148145\n",
      "126754        20929      think   0.143126\n",
      "69132         20205       know   0.138175\n",
      "118089        20174     source   0.137963\n",
      "49758         19180        get   0.131165\n",
      "50796         18377         go   0.125674\n",
      "4214          17458       also   0.119389\n",
      "127509        16465       time   0.112598\n",
      "94889         16105     people   0.110136\n",
      "1389          16097        add   0.110082\n",
      "133995        15739       user   0.107633\n",
      "14992         13722      block   0.093840\n",
      "138397        13507       well   0.092369\n",
      "85814         13318       need   0.091077\n",
      "78080         13274        may   0.090776\n",
      "124033        12885       take   0.088116\n",
      "51166         12880       good   0.088082\n",
      "137486        12801       want   0.087541\n",
      "...             ...        ...        ...\n",
      "83438          8085       much   0.055290\n",
      "8396           8051        ask   0.055058\n",
      "24636          7948       come   0.054353\n",
      "104017         7882     really   0.053902\n",
      "106983         7784     revert   0.053232\n",
      "78589          7712       mean   0.052740\n",
      "104097         7504     reason   0.051317\n",
      "18879          7429       call   0.050804\n",
      "115645         7428      since   0.050797\n",
      "38081          7381      edits   0.050476\n",
      "60491          7327    include   0.050107\n",
      "28047          7277     create   0.049765\n",
      "140890         7182       word   0.049115\n",
      "10466          7129       back   0.048753\n",
      "123877         7066        tag   0.048322\n",
      "88237          7060       note   0.048281\n",
      "98414          7058       post   0.048267\n",
      "117649         7011    someone   0.047946\n",
      "97724          6918     policy   0.047310\n",
      "139346         6901       wiki   0.047193\n",
      "71828          6880      leave   0.047050\n",
      "114801         6875       show   0.047016\n",
      "63603          6838      issue   0.046763\n",
      "130792         6795        two   0.046469\n",
      "56041          6758         hi   0.046215\n",
      "120480         6751       stop   0.046168\n",
      "142415         6747       year   0.046140\n",
      "120290         6734      still   0.046051\n",
      "26358          6709    content   0.045880\n",
      "101639         6442        put   0.044054\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df = 1)\n",
    "ctv = cv.fit_transform(preprocessed_train_data)\n",
    "ctv_freq = pd.DataFrame({'term': cv.get_feature_names(), 'occurrences':np.asarray(ctv.sum(axis=0)).ravel().tolist()})\n",
    "ctv_freq['frequency'] = ctv_freq['occurrences']/ctv_freq.shape[0]\n",
    "print (ctv_freq.sort_values('frequency', ascending = False).head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [‘red’ if c < 0 else ‘blue’ for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=’right’)\n",
    "    plt.show()\n",
    "\n",
    "cv = CountVectorizer()\n",
    "train = cv.fit_transform(preprocessed_train_data)\n",
    "\n",
    "\n",
    "svm = OneVsRestClassifier(LinearSVC(multi_class=\"ovr\")\n",
    "svm.fit(X_train, target)\n",
    "plot_coefficients(svm, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
