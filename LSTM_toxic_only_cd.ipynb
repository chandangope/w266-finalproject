{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChrisD/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "import tensorflow  as tf\n",
    "import keras\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.metrics import binary_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get full training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_all is entire training set, used for tokenization\n",
    "train_all=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get smaller sets for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toxic_yes_train\n",
    "toxic_yes_train=pd.read_csv('toxic_yes_train.txt',sep='\\n',header=-1)\n",
    "toxic_yes_train['toxic']=np.ones(toxic_yes_train.shape[0],)\n",
    "toxic_yes_train['toxic']=toxic_yes_train['toxic'].apply(lambda x: int(x))\n",
    "toxic_yes_train.columns=['comment','toxic']\n",
    "\n",
    "#toxic_no_train\n",
    "toxic_no_train=pd.read_csv('toxic_no_train.txt',sep='\\n',header=-1)\n",
    "toxic_no_train['toxic']=np.zeros(toxic_no_train.shape[0],)\n",
    "toxic_no_train['toxic']=toxic_no_train['toxic'].apply(lambda x: int(x))\n",
    "toxic_no_train.columns=['comment','toxic']\n",
    "\n",
    "\n",
    "#toxic_yes_dev\n",
    "toxic_yes_dev=pd.read_csv('toxic_yes_dev.txt',sep='\\n',header=-1)\n",
    "toxic_yes_dev['toxic']=np.ones(toxic_yes_dev.shape[0],)\n",
    "toxic_yes_dev['toxic']=toxic_yes_dev['toxic'].apply(lambda x: int(x))\n",
    "toxic_yes_dev.columns=['comment','toxic']\n",
    "\n",
    "#toxic_no_dev\n",
    "toxic_no_dev=pd.read_csv('toxic_no_dev.txt',sep='\\n',header=-1)\n",
    "toxic_no_dev['toxic']=np.zeros(toxic_no_dev.shape[0],)\n",
    "toxic_no_dev['toxic']=toxic_no_dev['toxic'].apply(lambda x: int(x))\n",
    "toxic_no_dev.columns=['comment','toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mix up the yes & no in each train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_dev=pd.concat([toxic_no_dev,toxic_yes_dev])\n",
    "toxic_dev = toxic_dev.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "toxic_train=pd.concat([toxic_no_train,toxic_yes_train])\n",
    "toxic_train = toxic_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "127658 train sequences\n",
      "31913 test sequences\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "\n",
    "print('Splitting data...')\n",
    "\n",
    "#training data\n",
    "x_train = toxic_train['comment'].fillna(\"nada\").values\n",
    "y_train = toxic_train[['toxic']].values\n",
    "\n",
    "#testing validation data (not for training model, just validation for )\n",
    "\n",
    "x_test = toxic_dev['comment'].fillna(\"nada\").values\n",
    "y_test = toxic_dev[['toxic']].values\n",
    "\n",
    "# check lengths\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_feature=20000\n",
    "EPOCHS=4\n",
    "maxlen=250 \n",
    "dropout=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_feature)\n",
    "\n",
    "tokenizer.fit_on_texts(list(train_all[\"comment_text\"].fillna(\"nada\").values)) #fit on all comment_text\n",
    "\n",
    "#create tokenized comments\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(x_train)  #training (80% of train.csv)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(x_test)  #testing (20% of train.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(maxlen,max_features,dropout,embed_size=128):\n",
    "    \n",
    "    embed_size=embed_size #default to 128\n",
    "    maxlen=maxlen # max length of sequence input\n",
    "    max_features=max_features  # max vocab\n",
    "    dropout=dropout\n",
    "    \n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    \n",
    "    x = Bidirectional(LSTM(50, return_sequences=False))(x)\n",
    "    \n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    \n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[binary_accuracy])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding maxlen= 250\n",
      "building model\n",
      "fitting model with max_features=20000, maxlen = 250, and dropout = 0.1\n",
      "Train on 114892 samples, validate on 12766 samples\n",
      "Epoch 1/4\n",
      "114892/114892 [==============================] - 1727s 15ms/step - loss: 0.1314 - binary_accuracy: 0.9547 - val_loss: 0.0998 - val_binary_accuracy: 0.9641\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09981, saving model to weights_base_20000_250_0.1_std_data.hdf5\n",
      "Epoch 2/4\n",
      "114892/114892 [==============================] - 1717s 15ms/step - loss: 0.0881 - binary_accuracy: 0.9671 - val_loss: 0.0998 - val_binary_accuracy: 0.9644\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/4\n",
      "114892/114892 [==============================] - 1707s 15ms/step - loss: 0.0664 - binary_accuracy: 0.9744 - val_loss: 0.1053 - val_binary_accuracy: 0.9619\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/4\n",
      "114892/114892 [==============================] - 1709s 15ms/step - loss: 0.0472 - binary_accuracy: 0.9817 - val_loss: 0.1417 - val_binary_accuracy: 0.9589\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "compiling model\n",
      "evaluating model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-78c45a03d302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluating model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "print('padding maxlen=',maxlen)\n",
    "x_train_sequence = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "x_test_sequence = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "\n",
    "print('building model')\n",
    "model=get_model(maxlen=maxlen,max_features=max_feature,dropout=dropout,embed_size=128)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "weight_file_path=\"weights_base_{}_{}_{}_std_data.hdf5\".format(max_feature,maxlen,dropout)\n",
    "model_file_path='bidirectional_lstm_relu_sigmoid_maxfeat{}_maxlen{}_dropout{}_std_data'.format(max_feature,maxlen,dropout)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "\n",
    "#fit model\n",
    "print('fitting model with max_features={}, maxlen = {}, and dropout = {}'.format(max_feature,maxlen,dropout))\n",
    "model.fit(x_train_sequence, y_train, batch_size=batch_size, epochs=EPOCHS, validation_split=0.1, callbacks=callbacks_list)\n",
    "\n",
    "#save model\n",
    "model.save(model_file_path)\n",
    "\n",
    "test_model=load_model(model_file_path)\n",
    "\n",
    "print('compiling model')\n",
    "test_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[binary_accuracy])\n",
    "\n",
    "print('evaluating model')\n",
    "score = test_model.evaluate(test_sequence, y_test, verbose=1)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (test_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "print('creating prediction')\n",
    "predict=test_model.predict(test_sequence, verbose=1)\n",
    "\n",
    "predict_df=pd.DataFrame(predict)\n",
    "predict_df.to_csv('bidirectional_lstm_relu_sigmoid_maxfeat{}_maxlen{}_dropout{}_std_data.csv'.format(max_feature,maxlen,dropout))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model\n",
      "31913/31913 [==============================] - 99s 3ms/step\n",
      "binary_accuracy: 96.00%\n",
      "creating prediction\n",
      "31913/31913 [==============================] - 98s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "print('evaluating model')\n",
    "score = test_model.evaluate(x_test_sequence, y_test, verbose=1)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (test_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "print('creating prediction')\n",
    "predict=test_model.predict(x_test_sequence, verbose=1)\n",
    "\n",
    "predict_df=pd.DataFrame(predict)\n",
    "predict_df.to_csv('bidirectional_lstm_relu_sigmoid_maxfeat{}_maxlen{}_dropout{}_std_data.csv'.format(max_feature,maxlen,dropout))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.293409e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.358924e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002165e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.600280e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.615242e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0  1.293409e-05\n",
       "1  5.358924e-07\n",
       "2  1.002165e-03\n",
       "3  2.600280e-04\n",
       "4  1.615242e-05"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test predictions on \"toxic\" category\n",
      "total true toxic 3058\n",
      "total false positive (incorrectly flagged as toxic) Type I 472\n",
      "false positive rate 15.435 %\n",
      "total false negative (omitted flagging as toxic) Type II 803\n",
      "false negative rate 26.259 %\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('test predictions on \"toxic\" category')\n",
    "predict_df=pd.DataFrame(predict)\n",
    "predict_df.columns=['toxic']\n",
    "\n",
    "predict_df.to_csv('prediction_2000_250_std_data.csv')\n",
    "\n",
    "for c in predict_df.columns:\n",
    "     predict_df[c]=predict_df[c].map(lambda x: 1 if x >=0.5 else 0)\n",
    "\n",
    "gold=pd.DataFrame(y_test)\n",
    "gold.columns=['toxic']\n",
    "        \n",
    "err_df=gold['toxic']-predict_df['toxic']  #val of -1 is false positive Type I, value of +1 is false negative Type II\n",
    "\n",
    "#performance_dict[key]['total_toxic']=sum(gold['toxic'])\n",
    "#performance_dict[key]['toxic_falsepos']=err_df.value_counts()[-1]\n",
    "#performance_dict[key]['toxic_falseneg']=err_df.value_counts()[1]\n",
    "\n",
    "\n",
    "\n",
    "print('total true toxic',sum(gold['toxic']))\n",
    "#false positives\n",
    "print('total false positive (incorrectly flagged as toxic) Type I',err_df.value_counts()[-1])\n",
    "print('false positive rate', '{:02.3f}'.format(100*err_df.value_counts()[-1]/sum(gold['toxic'])),'%')\n",
    "#false negatives\n",
    "print('total false negative (omitted flagging as toxic) Type II',err_df.value_counts()[1])\n",
    "print('false negative rate', '{:02.3f}'.format(100*err_df.value_counts()[1]/sum(gold['toxic'])),'%')\n",
    "\n",
    "\n",
    "print('-'*50,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(x_test),pd.DataFrame(err_df)], axis=1).to_csv('LSTM_std_data_error.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=pd.read_csv('LSTM_std_data_error.csv')\n",
    "dummy[dummy['toxic']==-1].to_csv('LSTM_std_error_falsePOS.csv',index=False)\n",
    "dummy[dummy['toxic']==1].to_csv('LSTM_std_error_falseNEG.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you simply display your ignorance fatuorum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ha do n't be silly you said that you were goin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and also admit being dick that time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boring ! ! ! ! ! ! stay out of it sister , go ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if a group of christians kill a hindu , do you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  toxic\n",
       "0         you simply display your ignorance fatuorum      1\n",
       "1  ha do n't be silly you said that you were goin...      1\n",
       "2                and also admit being dick that time      1\n",
       "3  boring ! ! ! ! ! ! stay out of it sister , go ...      1\n",
       "4  if a group of christians kill a hindu , do you...      1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('LSTM_std_error_falseNEG.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
